{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment template\n",
    "*This is an experiment template, used to auto-generate notebooks for new experiments*\n",
    "\n",
    "## Experiment description\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter helpers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from kmeans_poc.data import DataLoader\n",
    "from kmeans_poc.models import BaseModel\n",
    "from kmeans_poc.data_processing import DataProcessor\n",
    "from kmeans_poc.experimentation import MlflowExperimentation\n",
    "from src.evaluation import Evaluator, EvaluationMetrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "*replace MyDataLoader with your DataLoader implementation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = MyDataLoader()\n",
    "data_loader.download_dataset()\n",
    "dataset_for_modeling = data_loader.get_dataset()\n",
    "pickle_data = pickle.load(dataset_for_modeling)\n",
    "X_train, y_train = pickle_data['X_train'], pickle_data['y_train']\n",
    "X_test, y_test = pickle_data['X_test'], pickle_data['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Define experimentation object, which will be used for logging the experiments parameters, metrics and artifacts\n",
    "*Replace MlflowExperimentation if you use a different experimentation system*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentation = MlflowExperimentation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Create preprocessor for handling data preprocessing, feature engineering etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPreprocessor(DataProcessor):\n",
    "    def apply(self, X):\n",
    "        pass\n",
    "\n",
    "    def apply_batch(self, X):\n",
    "        pass\n",
    "\n",
    "preprocessor = MyPreprocessor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Create model/logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(BaseModel):\n",
    "    def fit(self, X, y=None, **fit_params) -> None:\n",
    "        pass\n",
    "\n",
    "    def predict(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "my_model = MyModel(preprocessor = preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Define evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class MyEvaluator(Evaluator):\n",
    "    def evaluate(self, **kwargs) -> EvaluationMetrics:\n",
    "        pass\n",
    "\n",
    "evaluator = MyEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_runner = ExperimentRunner(\n",
    "    model=model,\n",
    "    X_train=X_train,\n",
    "    y_train=y_train,\n",
    "    X_test=X_test,\n",
    "    y_test=y_test,\n",
    "    data_loader=data_loader,\n",
    "    log_experiment=True,\n",
    "    experiment_logger=experimentation,\n",
    "    evaluator=evaluator,\n",
    "    experiment_name=\"Experiment\",\n",
    ")\n",
    "\n",
    "results = experiment_runner.run()\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
